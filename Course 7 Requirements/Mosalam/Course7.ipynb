{"cells":[{"cell_type":"markdown","metadata":{"id":"ixemfpJOhs9m"},"source":["# Course #7 Resilience-Based Engineering: Cyber-Physical Modeling and Machine-Learning Towards Smart Electrical Equipment Systems\n","\n","Summer 2024 Semester<br>\n","Professor Khalid M. Mosalam<br>\n","SSA: Fan Hu<br>\n","Department of Civil and Environmental Engineering<br>\n","University of California, Berkeley<br>"]},{"cell_type":"markdown","metadata":{"id":"NeEaKKy5hs9n"},"source":["Welcome to Course 7: Cyber-Physical Modeling and Machine-Learning Towards Smart Electrical Equipment Systems. This notebook is meant to provide codes for your capstone project. Please read the __instructions__ as well as __comments in the code cells__ carefully.\n","\n","You are required to fill in the sections that are clearly marked with `TODO` and constrained with rows of pound signs (i.e. `#######`). An example code blank is shown in the following cell. Check this document for more details."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"u4kHHGC5hs9o"},"outputs":[{"name":"stdout","output_type":"stream","text":["Codes to edit/complete.\n"]}],"source":["# TODO: edit/complete the codes\n","####################################################################################################\n","\n","print(\"Codes to edit/complete.\") # Happy Coding :)\n","\n","####################################################################################################"]},{"cell_type":"markdown","metadata":{"id":"577QXkikhs9p"},"source":["We will be using some common Python libraries to help us process data. By convention, we import all libraries at the very top of the notebook. There are also a set of standard aliases that are used to shorten the library names (e.g., `np` for `numpy`). Run the cell below to import the libraries that you may need for this course project."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["!pip install tensorflow"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"NUqsEMV4hs9p"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'tensorflow'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m \u001b[38;5;66;03m# cannot use the alias 'tf' to import other modules\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"]}],"source":["import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","from matplotlib import image\n","import os\n","\n","import tensorflow as tf\n","\n","from tensorflow.keras.layers import * # cannot use the alias 'tf' to import other modules\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import *\n","from tensorflow.keras.optimizers import *\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"qNr2LBI1hs9p"},"source":["### Milestone 1"]},{"cell_type":"markdown","metadata":{"id":"WBGtVhEYhs9p"},"source":["For this part, you are expected to run a simple Finite Element Method (FEM) analysis on a porcelain insulator. Hand derivations of $[K]$ and $\\{P_0\\}$ for the whole structure is required, and this following (optional) chuck of code is to help you with matrix manipulations and output final displacement results. Below code uses $m=5$ (therefore $n=m+1=6$) as an example."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r43rIY6lhs9q"},"outputs":[],"source":["pi = math.pi\n","E = 70000\n","A = 17671\n","H = 4000\n","gamma = 3.5e-5\n","d_top = 100\n","d_bottom = 200\n","\n","# TODO: input K (dimenstion: 6x6) and P0 (dimension: 6)\n","# You have two options, 1) formulate the matrices using for-loop (recommended),\n","# OR 2) hand calculate the specific values of the matrices and fill in the blanks\n","# UNCOMMENT either option below.\n","####################################################################################################\n","\n","# OPTION1: for-loop (recommended)\n","\n","m = 5 #Number of elements\n","L_e = H / m  # Length of each element\n","A_top = np.pi * (d_top**2) / 4 #Calculate cross-sectional areas\n","A_bottom = np.pi * (d_bottom**2) / 4 #Calculate cross-sectional areas\n","\n","# Cross-sectional areas for each element (linearly varying)\n","A_e = np.linspace(A_top, A_bottom, m)\n","\n","# Initialize the matrices with zeros\n","K = np.zeros((m+1, m+1))\n","P0 = np.zeros(m+1)\n","\n","# Populate global stiffness matrix and load vector\n","for i in range(m):\n","    # Local stiffness matrix and load vector for element i\n","    ke = (E * A_e[i] / L_e) * np.array([[1, -1], [-1, 1]])\n","    p0e = (gamma * A_e[i] * L_e / 2) * np.array([1, 1])\n","\n","\n","# OPTION2: hard-coding\n","\"\"\"\n","K = np.array([\n","    [  ,  ,  ,  ,  ,  ],\n","    [  ,  ,  ,  ,  ,  ],\n","    [  ,  ,  ,  ,  ,  ],\n","    [  ,  ,  ,  ,  ,  ],\n","    [  ,  ,  ,  ,  ,  ],\n","    [  ,  ,  ,  ,  ,  ]\n","])\n","\n","P0 = np.array([\n","    [  ],\n","    [  ],\n","    [  ],\n","    [  ],\n","    [  ],\n","    [  ]\n","])\n","\"\"\"\n","####################################################################################################\n","\n","# Handle the boundary condition, see the project description\n","K = K[1:, 1:]\n","P0 = P0[1:]\n","\n","# Do the matrix inversion and multiplication to calculate the nodal displacements for node 2-n\n","U = np.dot(np.linalg.inv(K), -P0)\n","print(U)"]},{"cell_type":"markdown","metadata":{"id":"ZE4B3MDAhs9q"},"source":["### Milestone 2"]},{"cell_type":"markdown","metadata":{"id":"OnU_5Szwhs9q"},"source":["In this part, you are expected to complete the Python implementation of **Newmark's method** on linear systems."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fkkkmxjshs9r"},"outputs":[],"source":["# Two special cases of Newmark's method\n","# (1) Constant Average Acceleration Method\n","# gamma = 1/2\n","# beta = 1/4\n","\n","# (2) Linear Acceleration Method\n","gamma = 1/2\n","beta = 1/6"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8RtaKgaUhs9r"},"outputs":[],"source":["# TODO: Fill in the blanks below to implement Newmark's method\n","####################################################################################################\n","\n","m = 8000                         # kg\n","k = 36.4e6                       # N/m\n","zeta = 0.05                      # damping ratio\n","\n","wn = # TODO                      # rad/s\n","Tn = # TODO                      # s\n","wd = # TODO                      # rad/s\n","Td = # TODO                      # s\n","\n","c = # TODO                       # N*s/m\n","\n","\n","# Initial conditions\n","u_0 = 0\n","vel_0 = 0\n","\n","delta_t = 0.01 # time intervals\n","duration = 5\n","time_step = int(duration / delta_t)\n","t = np.arange(0, duration + delta_t, delta_t)\n","\n","p = 44500 * np.sin(20 * pi * t) * (t <= 0.6) # loading\n","p_0 = p[0]\n","\n","\n","# Initial calculations\n","acc_0 = # TODO\n","k_hat = # TODO\n","\n","a = # TODO\n","b = # TODO\n","\n","\n","# Calculations for each time step, i\n","acc = [acc_0]\n","vel = [vel_0]\n","u = [u_0]\n","\n","for i in range(0, time_step):\n","    delta_p_i = p[i+1] - p[i]\n","    delta_p_hat_i = # TODO\n","\n","    delta_u_i = # TODO\n","    delta_vel_i = # TODO\n","    delta_acc_i = # TODO\n","\n","    u.append(\"# TODO\")\n","    vel.append(\"# TODO\")\n","    acc.append(\"# TODO\")\n","\n","assert(len(u) == len(vel) == len(acc) == time_step + 1)\n","\n","####################################################################################################"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z_McsK9yhs9r"},"outputs":[],"source":["# TODO: Post-process the numerical results obtained\n","####################################################################################################\n","print(\"The maximum absolute displacement is\", \"# TODO\")\n","\n","plt.figure(figsize=[10, 8])\n","# TODO\n","plt.show()\n","####################################################################################################"]},{"cell_type":"markdown","metadata":{"id":"kvAXi3G7hs9r"},"source":["The cell below is provided for students to (optionally) solve the extra credit problem: Python implementation of another time integrator."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pbBTp-Ebhs9r"},"outputs":[],"source":["# TODO: extra credit problem\n","####################################################################################################\n","\n","\n","\n","####################################################################################################"]},{"cell_type":"markdown","metadata":{"id":"zkWQge4Nhs9s"},"source":["### Milestone 4"]},{"cell_type":"markdown","metadata":{"id":"GEpPQv9jhs9s"},"source":["For this part, you will train a Convolutional Neural Networks (CNN) classifier to identify the damages of transmission towers. You are expected to classify between undamaged/damaged states. Package `Keras` is used to train the CNN model, and the official documentation could be found in this [link](https://keras.io/guides/). For the layers and functions used below, you could search their names and find detailed explanations of the usage.\n","\n","Images are loaded as 3-D tensors using the `load_data()` helper function defined below. You will design the CNN architectures by filling in the parameters for the Keras layers. Consequently, the model will be created and trained, and the accuracy for the test set will be reported.\n","\n","You may want to read the comments carefully, and follow the instructions to complete the milestone. Specifically, you should design and fill in the architecture parameters of the classifier by following the comments that are marked with `CHOOSE`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HGKptKVuhs9s"},"outputs":[],"source":["'''\n","Helper function for DEWA course 7 Milestone 4.\n","\n","load_data() is used to load the images into NumPy arrays, which will be used in CNN classifiers later.\n","\n","'''\n","\n","def load_data(train_on_28=True):\n","    '''\n","    Load the data for CNN training.\n","    '''\n","\n","    train_data = []\n","    train_label = []\n","    test_data = []\n","    test_label = []\n","\n","    if (train_on_28):\n","        size = '28'\n","    else:\n","        size = '224'\n","\n","    size_n = int(size)\n","\n","    for file in os.listdir('Datasets/train_' + size + '/D/'):\n","        if (file[-4:] == \".jpg\"):\n","            train_data.append(image.imread('Datasets/train_' + size + '/D/' + file).reshape((size_n, size_n, 1)))\n","            train_label.append([0, 1])\n","    for file in os.listdir('Datasets/train_' + size + '/UD/'):\n","        if (file[-4:] == \".jpg\"):\n","            train_data.append(image.imread('Datasets/train_' + size + '/UD/' + file).reshape((size_n, size_n, 1)))\n","            train_label.append([1, 0])\n","    for file in os.listdir('Datasets/test_' + size + '/D/'):\n","        if (file[-4:] == \".jpg\"):\n","            test_data.append(image.imread('Datasets/test_' + size + '/D/' + file).reshape((size_n, size_n, 1)))\n","            test_label.append([0, 1])\n","    for file in os.listdir('Datasets/test_' + size + '/UD/'):\n","        if (file[-4:] == \".jpg\"):\n","            test_data.append(image.imread('Datasets/test_' + size + '/UD/' + file).reshape((size_n, size_n, 1)))\n","            test_label.append([1, 0])\n","\n","    train_data = np.array(train_data)\n","    train_label = np.array(train_label)\n","    test_data = np.array(test_data)\n","    test_label = np.array(test_label)\n","    return [train_data, train_label, test_data, test_label]"]},{"cell_type":"markdown","metadata":{"id":"nU1CaLLuhs9s"},"source":["Before starting the milestone, checked that you successfully installed packages keras and tensorflow by running the following code. No errors should be reported."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LwOkw3yVhs9s"},"outputs":[],"source":["print(\"TensorFlow version:\", tf.__version__)"]},{"cell_type":"markdown","metadata":{"id":"h1IDdwkYhs9s"},"source":["Some prior knowledge about **Batch Normalization**: (from CS182 Spring 2022 @ UC Berkeley)\n","\n","The main idea behind Batch Normalization is to transform every sampled batch of data so that they have $\\mu = 0$, $\\sigma^2 = 1$. Using Batch Normalization typically makes networks significantly more robust to poor initialization. It is based on the intuition that it is better to have unit Gaussian inputs to layers at initialization. However, the reason why batch normalization works is not entirely understood, and there are conflicting views between whether Batch Normalization reduces covariate shift, improves smoothness over the optimization landscape, or other reasons.\n","\n","In practice, when using batch normalization, we add a BatchNorm layer immediately _after_ each FC or convolutional layer, either _before_ or _after_ the non-linearity. The key observation is that normalization is a relatively simple differentiable operation, so we do not add too much additional complexity in the network."]},{"cell_type":"markdown","metadata":{"id":"lx3WT67Zhs9s"},"source":["Next, complete the codes below to train the classifier."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rk1e1zZehs9s"},"outputs":[],"source":["# Load the data\n","X_train, Y_train, X_test, Y_test = load_data(train_on_28=True)\n","\n","# Specify the model input data shape\n","X_input = Input((X_train.shape[1], X_train.shape[2], 1))\n","\n","\n","# TODO: choose values for the parameters specified in the comment that starts with CHOOSE\n","####################################################################################################\n","\n","# Apply the Convolutional layer to the images\n","# Padding is used to keep the image size same after Convolutional layer\n","# CHOOSE number of filters (filters). Recommended values are between 5 and 100\n","# CHOOSE filter size (kernel_size) in two directions. Recommended values are (3,3), (5,5), (7,7)\n","X = Conv2D(filters=    , kernel_size=(    ,    ), padding=\"same\")(X_input)\n","\n","# Use normalization to improve training performance\n","X = BatchNormalization(axis=3)(X)\n","\n","# CHOOSE an activation function: 'sigmoid', 'relu', 'tanh', etc\n","X = Activation('    ')(X)\n","\n","# CHOOSE pooling Layer: select between MaxPooling2D and AveragePooling2D\n","X = AveragePooling2D(pool_size=(2,2))(X)\n","\n","# Flatten X (i.e. convert the 3-D tensor into a 1-D vector)\n","X = Flatten()(X)\n","\n","# CHOOSE the number of Fully-Connected layers\n","# CHOOSE the number of neurons and an activation function ('sigmoid', 'relu', 'tanh', etc) for each layer\n","# Recommended number of layers is 2, as shown below\n","# The number of neurons for layers could be different,\n","# and it is recommended that later layers have less units\n","X = Dense(units=    , activation='    ')(X)\n","X = Dense(units=    , activation='    ')(X)\n","\n","\n","# Final output, Do NOT change the setting in this layer\n","Y_output = Dense(2, activation='softmax')(X)\n","\n","# Create the model. This creates your Keras model instance, you'll use this instance to train/test the model.\n","model = Model(inputs=X_input, outputs=Y_output)\n","\n","# Adam optimizer is used for training the model\n","# CHOOSE learning rate (lr): recommended values are between 1e-6 and 1e-3\n","optimizer = Adam(lr=    )\n","\n","# Compile the model\n","model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Learning rate is reduced when the loss is not decreasing\n","# Used to improve model performance\n","reduce_learning_rate = ReduceLROnPlateau(monitor='loss', factor=0.9, patience=20, verbose=1)\n","\n","# Train the model with training set images\n","# The verbose is turned on, so that students could observe the change of loss and training set accuracy for each epoch\n","# CHOOSE the number of epochs (epochs) and batch size (batch_size)\n","# Number of epochs are recommended to be between 20 and 1000\n","# Batch size should be between 1 and size of training data (362 in our case),\n","# and recommended values are powers of 2 (to improve efficiency in training)\n","model.fit(X_train, Y_train, epochs=    , verbose=True, batch_size=    , callbacks=[reduce_learning_rate])\n","\n","####################################################################################################\n","\n","# Output the test set accuracy by evaluating on the test set\n","print(\"The test set accuracy is {}\".format(model.evaluate(X_test, Y_test, verbose=False)[1]))"]},{"cell_type":"markdown","metadata":{"id":"X9c7MqINhs9t"},"source":["Now you have successfully trained a CNN! You may need to change the model architecture to improve the accuracy, or you may work with the larger size images (i.e., train_224, test_224) by using the following block of code. You may copy the parameters above into the block below as the start point to train on the larger dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZDCQio-Jhs9t"},"outputs":[],"source":["# Load the data\n","X_train, Y_train, X_test, Y_test = load_data(train_on_28=False)\n","\n","# Specify the model input data shape\n","X_input = Input((X_train.shape[1], X_train.shape[2], 1))\n","\n","\n","# TODO: choose values for the parameters specified in the comment that starts with CHOOSE\n","####################################################################################################\n","\n","# First layer\n","X = Conv2D(filters=    , kernel_size=(    ,    ), padding=\"same\")(X_input)\n","X = BatchNormalization(axis=3)(X)\n","X = Activation('    ')(X)\n","X = AveragePooling2D(pool_size=(2,2))(X)\n","\n","# Second layer\n","# You could use the same set of parameters as the first layer, or different set of parameters\n","X = Conv2D(filters=    , kernel_size=(    ,    ), padding=\"same\")(X)\n","X = BatchNormalization(axis=3)(X)\n","X = Activation('    ')(X)\n","X = AveragePooling2D(pool_size=(2,2))(X)\n","\n","# You can also add the third or more layers\n","\n","# Flatten X (i.e. convert the 3-D tensor into a vector)\n","X = Flatten()(X)\n","\n","# CHOOSE the number of Fully-Connected layers\n","# CHOOSE the number of neurons and an activation function ('sigmoid', 'relu', 'tanh', etc) for each layer\n","# Recommended number of layers is 2, as shown below\n","# The number of neurons for layers could be different,\n","# and it is recommended that later layers has less units\n","X = Dense(units=    , activation='    ')(X)\n","X = Dense(units=    , activation='    ')(X)\n","\n","# Final output, Do NOT change the setting in this layer\n","Y_output = Dense(2, activation='softmax')(X)\n","\n","# Create the model. This creates your Keras model instance, you'll use this instance to train/test the model.\n","model = Model(inputs=X_input, outputs=Y_output)\n","\n","# Adam optimizer is used for training the model\n","# CHOOSE learning rate (lr): recommended values are between 1e-6 and 1e-3\n","optimizer = Adam(lr=    )\n","\n","# Compile the model\n","model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Learning rate is reduced when the loss is not decreasing\n","# Used to improve model performance\n","reduce_learning_rate = ReduceLROnPlateau(monitor='loss', factor=0.9, patience=20, verbose=1)\n","\n","# Train the model with training set images\n","# The verbose is turned on, so that students could observe the change of loss and training set accuracy for each epoch\n","# CHOOSE the number of epochs (epochs) and batch size (batch_size)\n","# Number of epochs are recommended to be between 20 and 1000\n","# Batch size should be between 1 and size of training data (362 in our case),\n","# and recommended values are powers of 2 (to improve efficiency in training)\n","model.fit(X_train, Y_train, epochs=    , verbose=True, batch_size=    , callbacks=[reduce_learning_rate])\n","\n","####################################################################################################\n","\n","# Output the test set accuracy by evaluating on the test set\n","print(\"The test set accuracy is {}\".format(model.evaluate(X_test, Y_test, verbose=False)[1]))"]},{"cell_type":"markdown","metadata":{"id":"son9GAXChs9t"},"source":["The cell below is provided for students to (optionally) solve the extra credit problem: Classification using your own datasets."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yWNfeMjOhs9t"},"outputs":[],"source":["# TODO: extra credit problem\n","####################################################################################################\n","\n","\n","\n","####################################################################################################"]},{"cell_type":"markdown","metadata":{"id":"mrli4C0Dhs9t"},"source":["That's it for this milestone! You will need to submit this Jupyter Notebook with the report on Gradescope. Congrats for completing this course! :)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":0}
